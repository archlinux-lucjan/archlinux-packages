From ab0e36f9cecfdded9dec47e3e92a14d9f9de12a2 Mon Sep 17 00:00:00 2001
From: David Vernet <void@manifault.com>
Date: Mon, 18 Dec 2023 11:00:58 -0600
Subject: [PATCH 1/2] scx_nest: Apply r_impatient if no task is found in
 primary nest

Julia pointed out that our current implementation of r_impatient is
incorrect. r_impatient is meant to be a mechanism for more aggressively
growing the primary nest if a task repeatedly isn't able to find a core.
Right now, we trigger r_impatient if we're not able to find an attached
or previous core in the primary nest, but we _should_ be triggering it
only if we're unable to find _any_ core in the primary nest. Fixing the
implementation to do this drastically decreases how aggressively we grow
the primary nest when r_impatient is in effect.

Reported-by: Julia Lawall <julia.lawall@inria.fr>
Signed-off-by: David Vernet <void@manifault.com>
---
 scheds/c/scx_nest.bpf.c | 22 +++++++++++-----------
 1 file changed, 11 insertions(+), 11 deletions(-)

diff --git a/scheds/c/scx_nest.bpf.c b/scheds/c/scx_nest.bpf.c
index 0a279fb..cb69d85 100644
--- a/scheds/c/scx_nest.bpf.c
+++ b/scheds/c/scx_nest.bpf.c
@@ -207,7 +207,7 @@ s32 BPF_STRUCT_OPS(nest_select_cpu, struct task_struct *p, s32 prev_cpu,
 	s32 cpu;
 	struct task_ctx *tctx;
 	struct pcpu_ctx *pcpu_ctx;
-	bool direct_to_primary = false;
+	bool direct_to_primary = false, reset_impatient = true;

 	tctx = bpf_task_storage_get(&task_ctx_stor, p, 0, 0);
 	if (!tctx)
@@ -232,7 +232,6 @@ s32 BPF_STRUCT_OPS(nest_select_cpu, struct task_struct *p, s32 prev_cpu,
 	if (bpf_cpumask_test_cpu(tctx->attached_core, cast_mask(p_mask)) &&
 	    scx_bpf_test_and_clear_cpu_idle(tctx->attached_core)) {
 		cpu = tctx->attached_core;
-		tctx->prev_misses = 0;
 		stat_inc(NEST_STAT(WAKEUP_ATTACHED));
 		goto migrate_primary;
 	}
@@ -246,18 +245,10 @@ s32 BPF_STRUCT_OPS(nest_select_cpu, struct task_struct *p, s32 prev_cpu,
 	    bpf_cpumask_test_cpu(prev_cpu, cast_mask(p_mask)) &&
 	    scx_bpf_test_and_clear_cpu_idle(prev_cpu)) {
 		cpu = prev_cpu;
-		tctx->prev_misses = 0;
 		stat_inc(NEST_STAT(WAKEUP_PREV_PRIMARY));
 		goto migrate_primary;
 	}

-	if (r_impatient > 0 && ++tctx->prev_misses >= r_impatient) {
-		direct_to_primary = true;
-		tctx->prev_misses = 0;
-		stat_inc(NEST_STAT(TASK_IMPATIENT));
-		goto search_reserved;
-	}
-
 	if (find_fully_idle) {
 		/* Then try any fully idle core in primary. */
 		cpu = scx_bpf_pick_idle_cpu(cast_mask(p_mask),
@@ -275,7 +266,14 @@ s32 BPF_STRUCT_OPS(nest_select_cpu, struct task_struct *p, s32 prev_cpu,
 		goto migrate_primary;
 	}

-search_reserved:
+	if (r_impatient > 0 && ++tctx->prev_misses >= r_impatient) {
+		direct_to_primary = true;
+		tctx->prev_misses = 0;
+		stat_inc(NEST_STAT(TASK_IMPATIENT));
+	}
+
+	reset_impatient = false;
+
 	/* Then try any fully idle core in reserve. */
 	bpf_cpumask_and(p_mask, p->cpus_ptr, cast_mask(reserve));
 	if (find_fully_idle) {
@@ -336,6 +334,8 @@ s32 BPF_STRUCT_OPS(nest_select_cpu, struct task_struct *p, s32 prev_cpu,
 promote_to_primary:
 	stat_inc(NEST_STAT(PROMOTED_TO_PRIMARY));
 migrate_primary:
+	if (reset_impatient)
+		tctx->prev_misses = 0;
 	pcpu_ctx = bpf_map_lookup_elem(&pcpu_ctxs, &cpu);
 	if (pcpu_ctx) {
 		if (pcpu_ctx->scheduled_compaction) {

From 318c06fa9c8f70367401795ed98a2fa957367243 Mon Sep 17 00:00:00 2001
From: David Vernet <void@manifault.com>
Date: Mon, 18 Dec 2023 12:28:37 -0600
Subject: [PATCH 2/2] nest: Skip out of idle cpu selection on exec() path

The core sched code calls select_task_rq() in a few places: the task
wakeup path (typical path), the fork() path, and the exec() path. For
nest scheduling, we don't want to select a core from the nest on the
exec() path. If we were previously able to find an idle core, we would
have found it on the fork() path, so we don't gain much by checking on
the exec() path. In fact, it's actually harmful, because we could
incorrectly blow up the primary nest unnecessarily by bumping the same
task between multiple cores for no reason. Let's just opt-out of
select_task_rq calls on the exec() path.

Suggested-by: Julia Lawall <julia.lawall@inria.fr>
Signed-off-by: David Vernet <void@manifault.com>
---
 scheds/c/scx_nest.bpf.c | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/scheds/c/scx_nest.bpf.c b/scheds/c/scx_nest.bpf.c
index cb69d85..ce58649 100644
--- a/scheds/c/scx_nest.bpf.c
+++ b/scheds/c/scx_nest.bpf.c
@@ -209,6 +209,15 @@ s32 BPF_STRUCT_OPS(nest_select_cpu, struct task_struct *p, s32 prev_cpu,
 	struct pcpu_ctx *pcpu_ctx;
 	bool direct_to_primary = false, reset_impatient = true;

+	/*
+	 * Don't bother trying to find an idle core if a task is doing an
+	 * exec(). We would have already tried to find a core on fork(), and if
+	 * we were successful in doing so, the task will already be running on
+	 * what was previously an idle core.
+	 */
+	if (wake_flags & SCX_WAKE_EXEC)
+		return prev_cpu;
+
 	tctx = bpf_task_storage_get(&task_ctx_stor, p, 0, 0);
 	if (!tctx)
 		return -ENOENT;
